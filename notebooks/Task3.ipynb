{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "834546c8-abc5-43b8-a6ce-8d67e1bf9831",
   "metadata": {},
   "source": [
    "# Main logical components\n",
    "\n",
    "### data grabber\n",
    "- real cameras rarely produce data in some convenient representation, like popular image formats, and there become in use low level approaches like TCP/UDP, shared memory to transfer data. It is reasonable, cause cameras could produce enormous amount of data and work on big frame rates, like 100 or even 500 Hz or produce high accuracy data, like 32 bits.\n",
    "\n",
    "So, there should be component, that could grab data and represent it as something convenient in Python, example np.array.\n",
    "\n",
    "def grab() -> point_cloud (np.array), metadata (dict)\n",
    "\n",
    "### inference\n",
    "- component, that performs analysis: object detection, segmentation - not matters. It heavily use computation. It sould be done in the way, to enable all CPU-s and GPU-s, it case of Python it means usage of Multiprocessing, and queues and shared memory as much as possible. If we have cloud environment, there could be lot's of inference servers, and something to balance loading, lake RabbitMQ, python code, that split large task to smaller ones and than merge result.\n",
    "\n",
    "def infer(point_cloud, metadata) -> result (np.array), metadata (dict)\n",
    "\n",
    "### engine\n",
    "- orchestrates work of data grabber and inference, to make possible to fastly build similar APIs on different protocols. Like we could have HTTP, GRPS, just low level TCP/UDP API-s. It is like internal low-level API.\n",
    "\n",
    "def run_processing(request) -> response(result, metadata)\n",
    "\n",
    "### API\n",
    "- it could be HTTP (Flask, FastAPI, etc), GRPC or anything else, not much matters. It validates user request, check engine status, pass request to engine, validate results, send results back to user.\n",
    "\n",
    "def grab_latest_frame_and_detect_objects() -> result, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d0b95-c3c6-4497-af90-7aec4edaacae",
   "metadata": {},
   "source": [
    "# Problems that may arise during the deployment\n",
    "\n",
    "- deployment on different operating systems and CPU arcitectures could couse recompilation of some components and eaven there are situations, when components, only work with particular x64 or ARM arcitecture (same with operating systems). So, make as less dependencies and keep it in mind.\n",
    "- computer vision is very computation intensive and we should keep in mind, that on machine run not only object detection. So, communicate with other team members and estimate how much resources could consume every component, to not run-out RAM or CPU.\n",
    "- inter-process, inter-component communication. In the new environment could be not correctly configured network or file access, and we should make easy to use tools to check how data flows.\n",
    "- users in much cases need point cloud and analytics to be synchronized and we should carefully configure system to not overflow buffers and queues, and to avoid interlocks.\n",
    "- consider security issues, that deployment could be done in offline mode, and our Python solutions should be done in the way, to not be easy grabbed, to prevent stealing our algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
